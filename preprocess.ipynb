{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/.local/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_189756/3231634698.py\u001b[0m in \u001b[0;36m<cell line: 340>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0msid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.pt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# extrae SubjectID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubjects_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubjects_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SubjectID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0msid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgsex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1656\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1587\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1588\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1589\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m     \u001b[0;31m# -------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "###############################################################################\n",
    "# CONFIGURACIÓN DE LOGGING\n",
    "###############################################################################\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "###############################################################################\n",
    "# CONFIGURACIÓN Y RUTAS\n",
    "###############################################################################\n",
    "project_dir = '/home/diego/Escritorio/AAL_170'\n",
    "csv_path = os.path.join(project_dir, 'SubjectsDataAndTests.csv')\n",
    "tensor_data_dir = os.path.join(project_dir, 'TensorData')\n",
    "\n",
    "config_path = os.path.join(project_dir, 'config.yaml')\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "seed = config.get('seed', 42)\n",
    "n_splits = config.get('n_splits', 5)\n",
    "batch_size = config.get('batch_size', 16)\n",
    "\n",
    "apply_transforms = config.get('apply_transforms', True)\n",
    "apply_zscore = config.get('apply_zscore', True)\n",
    "\n",
    "transforms_config = config.get('transformations', {})\n",
    "#clamping_config = config.get('clamping', {})\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "###############################################################################\n",
    "# LECTURA DE METADATOS\n",
    "###############################################################################\n",
    "subjects_df = pd.read_csv(csv_path)\n",
    "\n",
    "def map_3class_group(x):\n",
    "    if x == 'AD':\n",
    "        return 'AD'\n",
    "    elif x == 'CN':\n",
    "        return 'CN'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "subjects_df['ResearchGroup'] = subjects_df['ResearchGroup'].apply(map_3class_group)\n",
    "subjects_df['Group_Sex'] = subjects_df['ResearchGroup'].astype(str) + '_' + subjects_df['Sex'].astype(str)\n",
    "\n",
    "###############################################################################\n",
    "# AGRUPACIÓN DE RUTAS .PT\n",
    "###############################################################################\n",
    "grouped_data = subjects_df.groupby(['ResearchGroup','Sex'])['SubjectID'].apply(list).to_dict()\n",
    "tensor_groups = {}\n",
    "for (group, sex), subject_ids in grouped_data.items():\n",
    "    file_paths = []\n",
    "    for sid in subject_ids:\n",
    "        if not os.path.exists(tensor_data_dir):\n",
    "            logging.warning(f\"No existe la carpeta de tensores: {tensor_data_dir}\")\n",
    "            continue\n",
    "        if group not in ['AD', 'CN']:\n",
    "            group = 'Other'\n",
    "        fp = os.path.join(tensor_data_dir, f\"{group}_tensor_{sid}.pt\")\n",
    "        file_paths.append(fp)\n",
    "    tensor_groups[f\"{group}_{sex}\"] = file_paths\n",
    "\n",
    "###############################################################################\n",
    "# FUNCIONES DE PREPROCESO\n",
    "###############################################################################\n",
    "def apply_channel_transforms(t: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Aplica solo las transformaciones que realmente quieras\n",
    "    sobre las 4 capas ya calculadas:\n",
    "      0: Correlación (Fisher-z)\n",
    "      1: NMI normalizado\n",
    "      2: Granger (–log p)\n",
    "      3: DCV (√var)\n",
    "    \"\"\"\n",
    "    if not apply_transforms:\n",
    "        return t\n",
    "\n",
    "    eps = 1e-8\n",
    "    # 0) Correlación: ya viene Fisher-z => solo escalar si lo pides\n",
    "    if transforms_config.get('scale_corr', False):\n",
    "        mu = t[0].mean()\n",
    "        sigma = t[0].std() + eps\n",
    "        t[0] = (t[0] - mu) / sigma\n",
    "\n",
    "    # 1) NMI: ya en [0,1] => escalado opcional\n",
    "    if transforms_config.get('scale_nmi', False):\n",
    "        mu = t[1].mean()\n",
    "        sigma = t[1].std() + eps\n",
    "        t[1] = (t[1] - mu) / sigma\n",
    "\n",
    "    # 2) Granger: ya es –log(p) => escalado opcional\n",
    "    if transforms_config.get('scale_gc', False):\n",
    "        mu = t[2].mean()\n",
    "        sigma = t[2].std() + eps\n",
    "        t[2] = (t[2] - mu) / sigma\n",
    "\n",
    "    # 3) DCV: ya es √var => escalado opcional\n",
    "    if transforms_config.get('scale_dcv', False):\n",
    "        mu = t[3].mean()\n",
    "        sigma = t[3].std() + eps\n",
    "        t[3] = (t[3] - mu) / sigma\n",
    "\n",
    "    return t\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def zero_diagonals(t: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Pone en 0 la diagonal de cada canal.\n",
    "    \"\"\"\n",
    "    t_out = t.clone()\n",
    "    C, H, W = t_out.shape\n",
    "    idx = torch.arange(H)\n",
    "    for c in range(C):\n",
    "        t_out[c, idx, idx] = 0.0\n",
    "    return t_out\n",
    "\n",
    "def load_tensor(fp: str):\n",
    "    \"\"\"\n",
    "    Retorna una tupla: (original, post_transform)\n",
    "    \n",
    "    - original: tal cual se lee de .pt (sin diagonal en cero, sin fisher/log/sqrt)\n",
    "    - post_transform: se aplican las transformaciones canal por canal\n",
    "      (Fisher, sqrt, log, etc.) y LUEGO se pone la diagonal en 0.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(fp):\n",
    "        logging.warning(f\"No existe el archivo: {fp}\")\n",
    "        return None, None\n",
    "    try:\n",
    "        data = torch.load(fp)  # shape (4,116,116) u otro\n",
    "        if isinstance(data, np.ndarray):\n",
    "            data = torch.tensor(data, dtype=torch.float32)\n",
    "        if not isinstance(data, torch.Tensor):\n",
    "            logging.warning(f\"Archivo {fp} con formato inesperado: {type(data)}\")\n",
    "            return None, None\n",
    "\n",
    "        # 1) original\n",
    "        original = data.clone()\n",
    "\n",
    "        # 2) apply transforms => luego zero diagonal\n",
    "        temp = apply_channel_transforms(data.clone())\n",
    "        post_transform = zero_diagonals(temp)\n",
    "\n",
    "        return original, post_transform\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error al cargar {fp}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def load_tensors(paths, batch_size=16):\n",
    "    \"\"\"\n",
    "    Carga las rutas en lotes, retorna (orig_all, post_all), cada uno shape (N,C,H,W).\n",
    "    \"\"\"\n",
    "    orig_list = []\n",
    "    post_list = []\n",
    "\n",
    "    for i in range(0, len(paths), batch_size):\n",
    "        batch_paths = paths[i:i+batch_size]\n",
    "        for p in batch_paths:\n",
    "            o, post = load_tensor(p)\n",
    "            if o is not None:\n",
    "                orig_list.append(o)\n",
    "                post_list.append(post)\n",
    "\n",
    "    if len(orig_list) == 0:\n",
    "        return None, None\n",
    "\n",
    "    orig_all = torch.stack(orig_list, dim=0)  # (N,C,H,W)\n",
    "    post_all = torch.stack(post_list, dim=0) # (N,C,H,W)\n",
    "    return orig_all, post_all\n",
    "\n",
    "def compute_mean_std_ignoring_diagonal(dataset: torch.Tensor):\n",
    "    \"\"\"\n",
    "    dataset: (N,C,H,W), ignora diagonal para mean/std\n",
    "    \"\"\"\n",
    "    N, C, H, W = dataset.shape\n",
    "    mask = torch.ones(H, W, dtype=bool)\n",
    "    mask[torch.arange(H), torch.arange(W)] = False\n",
    "\n",
    "    means = torch.zeros(C, dtype=torch.float32)\n",
    "    stds  = torch.zeros(C, dtype=torch.float32)\n",
    "\n",
    "    for c in range(C):\n",
    "        channel_data = dataset[:, c, :, :]\n",
    "        offdiag = channel_data[:, mask]\n",
    "        m = offdiag.mean()\n",
    "        s = offdiag.std()\n",
    "        if s < 1e-12:\n",
    "            s = 1e-9\n",
    "        means[c] = m\n",
    "        stds[c]  = s\n",
    "    return means, stds\n",
    "\n",
    "def zscore_ignoring_diagonal(dataset: torch.Tensor, mean_c: torch.Tensor, std_c: torch.Tensor):\n",
    "    \"\"\"\n",
    "    dataset: (N,C,H,W) => normaliza canal por canal, diagonal ya está en 0\n",
    "    \"\"\"\n",
    "    out = dataset.clone()\n",
    "    eps = 1e-9\n",
    "    for c in range(dataset.shape[1]):\n",
    "        out[:, c] = (out[:, c] - mean_c[c]) / (std_c[c] + eps)\n",
    "    return out\n",
    "\n",
    "###############################################################################\n",
    "# HISTOGRAMAS Y PLOTEO 3 FILAS\n",
    "###############################################################################\n",
    "def flatten_off_diagonal(data: torch.Tensor, c: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extrae off-diag del canal c en TODOS los sujetos.\n",
    "    data: (N,C,H,W)\n",
    "    \"\"\"\n",
    "    N, C_, H, W = data.shape\n",
    "    assert c < C_, \"Canal fuera de rango\"\n",
    "    mask = np.ones((H, W), dtype=bool)\n",
    "    np.fill_diagonal(mask, False)\n",
    "    channel_slice = data[:, c, :, :]\n",
    "    off_diag_vals = channel_slice[:, mask]\n",
    "    return off_diag_vals.flatten().cpu().numpy()\n",
    "\n",
    "def plot_histograms_3rows(\n",
    "    data_train_orig, data_val_orig, data_test_orig,\n",
    "    data_train_post, data_val_post, data_test_post,\n",
    "    data_train_z,    data_val_z,    data_test_z,\n",
    "    fold_idx\n",
    "):\n",
    "    \"\"\"\n",
    "    3 filas x 4 columnas:\n",
    "      Fila 0 => original\n",
    "      Fila 1 => post-transform\n",
    "      Fila 2 => post-transform + zscore\n",
    "\n",
    "    Cada fila muestra 3 histogramas (train/val/test) de off-diagonal.\n",
    "    \"\"\"\n",
    "    channel_names = [\"Correlation\", \"MI\", \"Granger\", \"DCV\"]\n",
    "    C = data_train_orig.shape[1]\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=3, ncols=C, figsize=(5*C, 12))\n",
    "    fig.suptitle(f\"Histogramas 3 estados (Fold {fold_idx})\", fontsize=15)\n",
    "    \n",
    "    def plot_hist(ax, values, color, label, bins=60, alpha=0.3):\n",
    "        ax.hist(values, bins=bins, alpha=alpha, color=color, label=label,\n",
    "                density=True, edgecolor='black')\n",
    "    \n",
    "    row_titles = [\"Original\", \"Post-Transform\", \"Post-Transform + Zscore\"]\n",
    "    \n",
    "    for c in range(C):\n",
    "        # --------------------------------------------------------------------\n",
    "        # Fila 0 => original\n",
    "        ax0 = axes[0, c]\n",
    "        tr_o = flatten_off_diagonal(data_train_orig, c)\n",
    "        vl_o = flatten_off_diagonal(data_val_orig,   c)\n",
    "        ts_o = flatten_off_diagonal(data_test_orig,  c)\n",
    "        plot_hist(ax0, tr_o, 'blue',   'Train')\n",
    "        plot_hist(ax0, vl_o, 'orange', 'Val')\n",
    "        plot_hist(ax0, ts_o, 'green',  'Test')\n",
    "        ax0.set_title(f\"{channel_names[c]} - {row_titles[0]}\")\n",
    "        ax0.legend()\n",
    "        \n",
    "        # --------------------------------------------------------------------\n",
    "        # Fila 1 => post-transform\n",
    "        ax1 = axes[1, c]\n",
    "        tr_pt = flatten_off_diagonal(data_train_post, c)\n",
    "        vl_pt = flatten_off_diagonal(data_val_post,   c)\n",
    "        ts_pt = flatten_off_diagonal(data_test_post,  c)\n",
    "        plot_hist(ax1, tr_pt, 'blue',   'Train')\n",
    "        plot_hist(ax1, vl_pt, 'orange', 'Val')\n",
    "        plot_hist(ax1, ts_pt, 'green',  'Test')\n",
    "        ax1.set_title(f\"{channel_names[c]} - {row_titles[1]}\")\n",
    "        ax1.legend()\n",
    "        \n",
    "        # --------------------------------------------------------------------\n",
    "        # Fila 2 => post-transform + zscore\n",
    "        ax2 = axes[2, c]\n",
    "        tr_z = flatten_off_diagonal(data_train_z, c)\n",
    "        vl_z = flatten_off_diagonal(data_val_z,   c)\n",
    "        ts_z = flatten_off_diagonal(data_test_z,  c)\n",
    "        plot_hist(ax2, tr_z, 'blue',   'Train')\n",
    "        plot_hist(ax2, vl_z, 'orange', 'Val')\n",
    "        plot_hist(ax2, ts_z, 'green',  'Test')\n",
    "        ax2.set_title(f\"{channel_names[c]} - {row_titles[2]}\")\n",
    "        ax2.legend()\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_4matrices_3rows(\n",
    "    m_orig: torch.Tensor,       # shape (C,H,W)\n",
    "    m_post: torch.Tensor,       # shape (C,H,W)\n",
    "    m_post_z: torch.Tensor,     # shape (C,H,W)\n",
    "    fold_idx: int,\n",
    "    subject_idx: int\n",
    "):\n",
    "    \"\"\"\n",
    "    3 filas x 4 columnas:\n",
    "      - Fila 0 => original\n",
    "      - Fila 1 => post-transform\n",
    "      - Fila 2 => post-transform + z-score\n",
    "\n",
    "    Columnas => cada canal.\n",
    "    \"\"\"\n",
    "    titles = [\"Correlation\", \"MI\", \"Granger\", \"DCV\"]\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(20, 12))\n",
    "    fig.suptitle(f\"Fold {fold_idx} - Sujeto {subject_idx} (3 filas: original, post-trans, +zscore)\", fontsize=15)\n",
    "\n",
    "    row_titles = [\"Original\", \"Post-Transform\", \"Post-Transform + Zscore\"]\n",
    "    data_list = [m_orig, m_post, m_post_z]\n",
    "    \n",
    "    for row_idx in range(3):\n",
    "        mat = data_list[row_idx]\n",
    "        for c in range(4):\n",
    "            ax = axes[row_idx, c]\n",
    "            im = ax.imshow(mat[c].cpu().numpy(), aspect='auto', cmap='jet')\n",
    "            ax.set_title(f\"{titles[c]} - {row_titles[row_idx]}\")\n",
    "            plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    plt.tight_layout(rect=[0,0,1,0.93])\n",
    "    plt.show()\n",
    "\n",
    "###############################################################################\n",
    "# CROSS-VALIDATION\n",
    "###############################################################################\n",
    "X, y, sex, ages = [], [], [], []\n",
    "for gsex, file_paths in tensor_groups.items():\n",
    "    for fp in file_paths:\n",
    "        sid = os.path.basename(fp).split('_')[-1].replace('.pt','')  # extrae SubjectID\n",
    "        row = subjects_df[subjects_df['SubjectID']==sid].iloc[0]\n",
    "        X.append(fp)\n",
    "        y.append(gsex)\n",
    "        sex.append(row['Sex'])\n",
    "        ages.append(row['Age'])\n",
    "X = np.array(X); y = np.array(y)\n",
    "sex = np.array(sex)      # e.g. ['M','F','M',...]\n",
    "ages = np.array(ages, dtype=float)\n",
    "\n",
    "logging.info(f\"Total de sujetos en CSV: {len(subjects_df)}\")\n",
    "logging.info(f\"Total de rutas generadas en X: {len(X)}\")\n",
    "logging.info(f\"Distribución de y: {np.unique(y, return_counts=True)}\")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "fold_number = 1\n",
    "\n",
    "for train_val_idx, test_idx in skf.split(X, y):\n",
    "    X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "    sex_train_val, sex_test = sex[train_val_idx], sex[test_idx]\n",
    "    age_train_val, age_test = ages[train_val_idx], ages[test_idx]\n",
    "\n",
    "    # Separar train vs val (80/20 estratificado)\n",
    "    tv_idx = np.arange(len(X_train_val))\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        np.arange(len(X_train_val)), test_size=0.2,\n",
    "        stratify=y_train_val, random_state=seed)\n",
    "    X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "    y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "    sex_train, sex_val = sex_train_val[train_idx], sex_train_val[val_idx]\n",
    "    age_train, age_val = age_train_val[train_idx], age_train_val[val_idx]\n",
    "\n",
    "    # 1) Cargar => (orig, post)\n",
    "    (train_orig, train_post) = load_tensors(X_train)\n",
    "    (val_orig,   val_post)   = load_tensors(X_val)\n",
    "    (test_orig,  test_post)  = load_tensors(X_test)\n",
    "\n",
    "    from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "    # 3.1 One-hot del sexo\n",
    "    ohe = OneHotEncoder(sparse=False, dtype=np.float32)\n",
    "    sex_train_ohe = ohe.fit_transform(sex_train.reshape(-1,1))\n",
    "    sex_val_ohe   = ohe.transform(sex_val.reshape(-1,1))\n",
    "    sex_test_ohe  = ohe.transform(sex_test.reshape(-1,1))\n",
    "\n",
    "    # 3.2 Normalizar edad (z-score sobre TRAIN)\n",
    "    age_scaler = StandardScaler()\n",
    "    age_train_z = age_scaler.fit_transform(age_train.reshape(-1,1))\n",
    "    age_val_z   = age_scaler.transform(age_val.reshape(-1,1))\n",
    "    age_test_z  = age_scaler.transform(age_test.reshape(-1,1))\n",
    "\n",
    "    # 3.3 Combinar clinical features\n",
    "    clin_train = np.hstack([sex_train_ohe, age_train_z])  # forma (N_train, 2+1)\n",
    "    clin_val   = np.hstack([sex_val_ohe,   age_val_z  ])\n",
    "    clin_test  = np.hstack([sex_test_ohe,  age_test_z ])\n",
    "\n",
    "\n",
    "    # Verificar sets vacíos\n",
    "    if train_orig is None or val_orig is None or test_orig is None:\n",
    "        logging.warning(f\"Faltan datos en fold {fold_number}. Omitiendo...\")\n",
    "        fold_number += 1\n",
    "        continue\n",
    "\n",
    "    n_train = train_orig.shape[0]\n",
    "    n_val   = val_orig.shape[0]\n",
    "    n_test  = test_orig.shape[0]\n",
    "    logging.info(f\"FOLD {fold_number} => Train: {n_train}, Val: {n_val}, Test: {n_test}\")\n",
    "\n",
    "    # 2) z-score => se calcula la media/std en train_post\n",
    "    mean_c, std_c = compute_mean_std_ignoring_diagonal(train_post)\n",
    "\n",
    "    if apply_zscore:\n",
    "        train_z = zscore_ignoring_diagonal(train_post, mean_c, std_c)\n",
    "        val_z   = zscore_ignoring_diagonal(val_post,   mean_c, std_c)\n",
    "        test_z  = zscore_ignoring_diagonal(test_post,  mean_c, std_c)\n",
    "    else:\n",
    "        train_z = train_post.clone()\n",
    "        val_z   = val_post.clone()\n",
    "        test_z  = test_post.clone()\n",
    "\n",
    "\n",
    "    # 3) Graficar histogramas con 3 filas (original, post, post+zscore)\n",
    "    plot_histograms_3rows(\n",
    "        data_train_orig=train_orig,  data_val_orig=val_orig,   data_test_orig=test_orig,\n",
    "        data_train_post=train_post,  data_val_post=val_post,   data_test_post=test_post,\n",
    "        data_train_z=train_z,        data_val_z=val_z,         data_test_z=test_z,\n",
    "        fold_idx=fold_number\n",
    "    )\n",
    "\n",
    "    # 4) Elegir 1 sujeto random del train y mostrar sus 4 canales en 3 filas\n",
    "    random_idx = random.randint(0, n_train - 1)\n",
    "    m_orig = train_orig[random_idx]   # shape (C,H,W)\n",
    "    m_post = train_post[random_idx]\n",
    "    m_z    = train_z[random_idx]\n",
    "    plot_4matrices_3rows(\n",
    "        m_orig=m_orig,\n",
    "        m_post=m_post,\n",
    "        m_post_z=m_z,\n",
    "        fold_idx=fold_number,\n",
    "        subject_idx=random_idx\n",
    "    )\n",
    "\n",
    "    # 5) Guardar resultados en disco\n",
    "    fold_dir = os.path.join(project_dir, f\"fold_{fold_number}\")\n",
    "    os.makedirs(fold_dir, exist_ok=True)\n",
    "\n",
    "    torch.save(train_orig, os.path.join(fold_dir, 'train_original.pt'))\n",
    "    torch.save(train_post, os.path.join(fold_dir, 'train_post.pt'))\n",
    "    torch.save(train_z,    os.path.join(fold_dir, 'train_z.pt'))\n",
    "\n",
    "    torch.save(val_orig, os.path.join(fold_dir, 'val_original.pt'))\n",
    "    torch.save(val_post, os.path.join(fold_dir, 'val_post.pt'))\n",
    "    torch.save(val_z,    os.path.join(fold_dir, 'val_z.pt'))\n",
    "\n",
    "    torch.save(test_orig, os.path.join(fold_dir, 'test_original.pt'))\n",
    "    torch.save(test_post, os.path.join(fold_dir, 'test_post.pt'))\n",
    "    torch.save(test_z,    os.path.join(fold_dir, 'test_z.pt'))\n",
    "\n",
    "    torch.save(y_train, os.path.join(fold_dir, 'train_labels.pt'))\n",
    "    torch.save(y_val,   os.path.join(fold_dir, 'val_labels.pt'))\n",
    "    torch.save(y_test,  os.path.join(fold_dir, 'test_labels.pt'))\n",
    "\n",
    "    import json\n",
    "    fold_stats = {\n",
    "        'means': mean_c.tolist(),\n",
    "        'stds':  std_c.tolist()\n",
    "    }\n",
    "    with open(os.path.join(fold_dir, 'train_stats.json'), 'w') as fjs:\n",
    "        json.dump(fold_stats, fjs, indent=2)\n",
    "\n",
    "    logging.info(f\"[Fold {fold_number}] => Datos y estadísticas guardados en {fold_dir}\")\n",
    "    fold_number += 1\n",
    "\n",
    "logging.info(\"Proceso de Cross-Validation completo.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
